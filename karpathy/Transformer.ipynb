{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e74cf4e-ed9c-4321-8074-60403953d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371a08fd-0051-4fdf-ba50-d185419a3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, dims:int, heads:int, block_size:int, dropout:float=0.1):\n",
    "        \n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        \n",
    "        # number of dims must be evenly divisible by num heads\n",
    "        assert dims % heads == 0\n",
    "        \n",
    "        self.dims = dims\n",
    "        self.heads = heads\n",
    "        self.block_size = block_size\n",
    "        self.head_dims = dims // heads\n",
    "        self.dk_sqrt = math.sqrt(self.head_dims)\n",
    "        \n",
    "        self.register_buffer('mask', torch.tril(torch.ones(self.block_size, self.block_size)) \\\n",
    "                             .view(1,1,self.block_size, self.block_size))\n",
    "        \n",
    "        self.qkv_projection = nn.Linear(self.dims,self.dims * 3)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.out_projection = nn.Linear(self.dims,self.dims)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def calculate_attention(self, q, k, v, T):\n",
    "        \n",
    "        # get similarity of key and query via dot product\n",
    "        qk_similarity = q @ k.transpose(-2, -1)\n",
    "        # normalize values by head dims\n",
    "        normalized_qk_similarity = qk_similarity / self.dk_sqrt\n",
    "        attention = normalized_qk_similarity.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))\n",
    "        attention = torch.softmax(normalized_qk_similarity, dim=-1)\n",
    "        attention = self.attn_dropout(attention)\n",
    "        out = attention @ v\n",
    "        \n",
    "        return out, attention\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, T, C = x.shape # batch size, num tokens, token embedding size\n",
    "        \n",
    "        # linear projection for q, k, v\n",
    "        qkv = self.qkv_projection(x).split(self.dims, dim=2)\n",
    "        \n",
    "        # reshape to (batch, heads, tokens, head_dims)\n",
    "        q, k, v = [cv.view((B, -1, self.heads, self.head_dims)).transpose(1, 2) for cv in qkv]\n",
    "        \n",
    "        # calculatue and apply attention\n",
    "        y, attention = self.calculate_attention(q, k, v, T)\n",
    "        \n",
    "        # concat all heads\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        \n",
    "        # outward projection and residual dropout\n",
    "        y = self.resid_dropout(self.out_projection(y))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03c7d91-af36-4bd4-9d7e-9ce633f510fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiHeadedAttention(100, 20, 100)\n",
    "x = torch.randn(3, 12, 100)\n",
    "model(model(x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e6bd50-fa53-4c31-a2e6-ec0a3aa265a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dims:int, block_size:int):\n",
    "        \n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        \n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.block_size = block_size\n",
    "        \n",
    "        positional_embedding = torch.zeros(block_size, embedding_dims)\n",
    "        div_pos = torch.arange(0, self.embedding_dims, 2)\n",
    "        divisors = torch.exp(div_pos * -(math.log(10000.0) / self.embedding_dims))\n",
    "        positions = torch.arange(block_size)[:,None,...]\n",
    "        \n",
    "        positional_embedding[:, 0::2] = torch.sin(positions * divisors)\n",
    "        positional_embedding[:, 1::2] = torch.cos(positions * divisors)\n",
    "        positional_embedding = positional_embedding[None,...]\n",
    "        \n",
    "        self.register_buffer('positional_embedding', positional_embedding)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = Variable(x + self.positional_embedding[:, :x.shape[1]], requires_grad=False)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92f8732-33d6-46d8-bcc7-63d6a66a06a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dims:int, hidden_dims:int, dropout:float=0.1):\n",
    "        \n",
    "        super(PositionWiseFFN, self).__init__()\n",
    "        \n",
    "        self.sequence = nn.Sequential(\n",
    "            nn.Linear(in_dims, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, in_dims),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)\n",
    "    \n",
    "pwffn = PositionWiseFFN(10, 100)\n",
    "pwffn(torch.randn(5,10,10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6576369-b47f-4fda-b910-547ca69b483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 att_heads:int = 8, \n",
    "                 att_dims:int = 64,\n",
    "                 block_size:int = 64\n",
    "                ):\n",
    "        \n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        self.att_heads = att_heads\n",
    "        self.att_dims = att_dims\n",
    "        self.block_size = block_size\n",
    "        \n",
    "        self.ln_1 = nn.LayerNorm(self.att_dims)\n",
    "        self.attention = MultiHeadedAttention(self.att_dims, self.att_heads, self.block_size)\n",
    "        self.ln_2 = nn.LayerNorm(self.att_dims)\n",
    "        self.feed_forward = PositionWiseFFN(self.att_dims, 4 * self.att_dims)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x + self.attention(self.ln_1(x))\n",
    "        x = x + self.feed_forward(self.ln_2(x))\n",
    "        \n",
    "        return x\n",
    "        \n",
    "tb = TransformerBlock()\n",
    "x = torch.randn((3,12,64))\n",
    "tb(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5495c2e9-f709-4e37-86cc-10dc18d51dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 vocab_size:int = 32,\n",
    "                 block_size:int = 64,\n",
    "                 embedding_dims:int = 64,\n",
    "                 att_heads:int = 8,\n",
    "                 layers:int = 3,\n",
    "                 dropout:float = 0.1\n",
    "                ):\n",
    "        \n",
    "        super(DecoderTransformer, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.block_size = block_size\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.att_heads = att_heads\n",
    "        \n",
    "        self.sequence = nn.Sequential(\n",
    "            nn.Embedding(self.vocab_size, self.embedding_dims),\n",
    "            PositionalEncoder(self.embedding_dims, self.block_size), # maybe just change this to an embedding too\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Sequential(*[TransformerBlock(self.att_heads, self.embedding_dims, self.block_size) for _ in range(layers)]),\n",
    "            nn.LayerNorm(self.embedding_dims)\n",
    "        )\n",
    "        \n",
    "        self.lm_head = nn.Linear(self.embedding_dims, self.vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.sequence(x)\n",
    "        return self.lm_head(x)\n",
    "\n",
    "model = DecoderTransformer()\n",
    "x = torch.randint(31, (4,64))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b202b80-2643-4dec-8ea5-d851ba179aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('./names.txt').read().splitlines()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2870af15-9e49-45d9-b4e2-d1f2b9808a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words)))) #lol\n",
    "token_lookup = {c: i+1 for i, c in enumerate(chars)}\n",
    "token_lookup['.'] = 0\n",
    "char_lookup = {i:c for c, i in token_lookup.items()}\n",
    "TOTAL_TOKENS = len(char_lookup.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a43434ea-0470-4f69-bad6-0b29f23fb3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182413, 8]) torch.Size([182413])\n",
      "torch.Size([22947, 8]) torch.Size([22947])\n",
      "torch.Size([22786, 8]) torch.Size([22786])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "BLOCK_SIZE = 8 # context size to give the model in order to predict the next character\n",
    "\n",
    "def build_dataset(corpus, block_size, codebook, padding_char=\".\"):\n",
    "    X, Y = [], []\n",
    "    for word in corpus:\n",
    "        start_padding = padding_char * block_size\n",
    "        padded_word = f\"{start_padding}{word}.\"\n",
    "        tokenized_word = [codebook[c] for c in padded_word]\n",
    "        for i in range(len(tokenized_word)-block_size):\n",
    "            X.append(tokenized_word[i:i+block_size])\n",
    "            Y.append(tokenized_word[i+block_size])\n",
    "        \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    \n",
    "    print(X.shape, Y.shape)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "random.shuffle(words)\n",
    "\n",
    "n1 = int(len(words)*0.8)\n",
    "n2 = int(len(words)*0.9)\n",
    "\n",
    "x_train, y_train = build_dataset(words[:n1], BLOCK_SIZE, token_lookup)\n",
    "x_valid, y_valid = build_dataset(words[n1:n2], BLOCK_SIZE, token_lookup)\n",
    "x_test, y_test = build_dataset(words[n2:], BLOCK_SIZE, token_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d90bb7a4-5811-4e7d-92bd-3a2bbe94f5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 2.01: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:21<00:00, 122.86it/s]\n"
     ]
    }
   ],
   "source": [
    "model = DecoderTransformer()\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "device = 'cuda:1'\n",
    "steps = 10000\n",
    "print_steps = 2000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "losses = []\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "pbar = tqdm(range(steps))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for t in pbar:\n",
    "    batch_ix = torch.randint(0, x_train.shape[0], (BATCH_SIZE,))\n",
    "    batch = x_train[batch_ix].to(device)\n",
    "    logits = model(batch).mean(1)\n",
    "    \n",
    "    #plucked_logits = logits[:,0::BLOCK_SIZE].view(-1, logits.shape[-1])\n",
    "    loss = F.cross_entropy(logits, y_train[batch_ix].to(device))\n",
    "    losses.append(loss.item())\n",
    "    pbar.set_description(desc=f'average loss: {(sum(losses[-100:])/100):.2f}')\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "941a75b2-4db7-43b4-95a0-9e9ea6692cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(losses).view(-1, 250).mean(1))\n",
    "plt.title(\"average loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3db0f84-3089-4a26-8aef-9b465211ff88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('train', 1.9699320793151855), ('val', 2.016996383666992))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.train(False)\n",
    "\n",
    "# clculate training and validation loss\n",
    "@torch.no_grad()\n",
    "def calc_loss(x_target, y_target):\n",
    "    logits = model(x_target).mean(1)\n",
    "    #plucked_logits = logits[:,0::BLOCK_SIZE].view(-1, logits.shape[-1])\n",
    "    loss = F.cross_entropy(logits, y_target)\n",
    "    return loss\n",
    "\n",
    "('train', calc_loss(x_train, y_train).item()), ('val', calc_loss(x_valid, y_valid).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1801a71a-53ff-4acf-823a-ffde1468015b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kandron\n",
      "tai\n",
      "dorader\n",
      "jazleeigh\n",
      "samila\n",
      "rosett\n",
      "illiana\n",
      "phile\n",
      "gebioli\n",
      "petram\n",
      "maven\n",
      "kolson\n",
      "quinstafud\n",
      "khilder\n",
      "daydynn\n",
      "samarius\n",
      "ella\n",
      "anurmana\n",
      "liley\n",
      "aave\n"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "@torch.no_grad()\n",
    "def sample():\n",
    "    tokens = [0] * BLOCK_SIZE\n",
    "    while True:\n",
    "        cur_tokens = torch.tensor(tokens[-BLOCK_SIZE:]).unsqueeze(0)\n",
    "        logits = model(cur_tokens).squeeze()\n",
    "        probs = F.softmax(logits.mean(0), dim=0)\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "        tokens.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    return \"\".join([char_lookup[t] for t in tokens][BLOCK_SIZE:-1])\n",
    "\n",
    "for i in range(20):\n",
    "    print(sample())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
