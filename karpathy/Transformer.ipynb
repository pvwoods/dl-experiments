{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e74cf4e-ed9c-4321-8074-60403953d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371a08fd-0051-4fdf-ba50-d185419a3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, dims:int, heads:int, block_size:int, dropout:float=0.1):\n",
    "        \n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        \n",
    "        # number of dims must be evenly divisible by num heads\n",
    "        assert dims % heads == 0\n",
    "        \n",
    "        self.dims = dims\n",
    "        self.heads = heads\n",
    "        self.block_size = block_size\n",
    "        self.head_dims = dims // heads\n",
    "        self.dk_sqrt = math.sqrt(self.head_dims)\n",
    "        \n",
    "        self.register_buffer('mask', torch.tril(torch.ones(self.block_size, self.block_size)) \\\n",
    "                             .view(1,1,self.block_size, self.block_size))\n",
    "        \n",
    "        self.qkv_projection = nn.Linear(self.dims,self.dims * 3)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.out_projection = nn.Linear(self.dims,self.dims)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def calculate_attention(self, q, k, v, T):\n",
    "        \n",
    "        # get similarity of key and query via dot product\n",
    "        qk_similarity = q @ k.transpose(-2, -1)\n",
    "        # normalize values by head dims\n",
    "        normalized_qk_similarity = qk_similarity / self.dk_sqrt\n",
    "        attention = normalized_qk_similarity.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))\n",
    "        attention = torch.softmax(normalized_qk_similarity, dim=-1)\n",
    "        attention = self.attn_dropout(attention)\n",
    "        out = attention @ v\n",
    "        \n",
    "        return out, attention\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, T, C = x.shape # batch size, num tokens, token embedding size\n",
    "        \n",
    "        # linear projection for q, k, v\n",
    "        qkv = self.qkv_projection(x).split(self.dims, dim=2)\n",
    "        \n",
    "        # reshape to (batch, heads, tokens, head_dims)\n",
    "        q, k, v = [cv.view((B, -1, self.heads, self.head_dims)).transpose(1, 2) for cv in qkv]\n",
    "        \n",
    "        # calculatue and apply attention\n",
    "        y, attention = self.calculate_attention(q, k, v, T)\n",
    "        \n",
    "        # concat all heads\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        \n",
    "        # outward projection and residual dropout\n",
    "        y = self.resid_dropout(self.out_projection(y))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03c7d91-af36-4bd4-9d7e-9ce633f510fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiHeadedAttention(100, 20, 100)\n",
    "x = torch.randn(3, 12, 100)\n",
    "model(model(x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e6bd50-fa53-4c31-a2e6-ec0a3aa265a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dims:int, block_size:int):\n",
    "        \n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        \n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.block_size = block_size\n",
    "        \n",
    "        positional_embedding = torch.zeros(block_size, embedding_dims)\n",
    "        div_pos = torch.arange(0, self.embedding_dims, 2)\n",
    "        divisors = torch.exp(div_pos * -(math.log(10000.0) / self.embedding_dims))\n",
    "        positions = torch.arange(block_size)[:,None,...]\n",
    "        \n",
    "        positional_embedding[:, 0::2] = torch.sin(positions * divisors)\n",
    "        positional_embedding[:, 1::2] = torch.cos(positions * divisors)\n",
    "        positional_embedding = positional_embedding[None,...]\n",
    "        \n",
    "        self.register_buffer('positional_embedding', positional_embedding)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = Variable(x + self.positional_embedding[:, :x.shape[1]], requires_grad=False)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92f8732-33d6-46d8-bcc7-63d6a66a06a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dims:int, hidden_dims:int, dropout:float=0.1):\n",
    "        \n",
    "        super(PositionWiseFFN, self).__init__()\n",
    "        \n",
    "        self.sequence = nn.Sequential(\n",
    "            nn.Linear(in_dims, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, in_dims),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)\n",
    "    \n",
    "pwffn = PositionWiseFFN(10, 100)\n",
    "pwffn(torch.randn(5,10,10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6576369-b47f-4fda-b910-547ca69b483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 att_heads:int = 8, \n",
    "                 att_dims:int = 64,\n",
    "                 block_size:int = 64\n",
    "                ):\n",
    "        \n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        self.att_heads = att_heads\n",
    "        self.att_dims = att_dims\n",
    "        self.block_size = block_size\n",
    "        \n",
    "        self.ln_1 = nn.LayerNorm(self.att_dims)\n",
    "        self.attention = MultiHeadedAttention(self.att_dims, self.att_heads, self.block_size)\n",
    "        self.ln_2 = nn.LayerNorm(self.att_dims)\n",
    "        self.feed_forward = PositionWiseFFN(self.att_dims, 4 * self.att_dims)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x + self.attention(self.ln_1(x))\n",
    "        x = x + self.feed_forward(self.ln_2(x))\n",
    "        \n",
    "        return x\n",
    "        \n",
    "tb = TransformerBlock()\n",
    "x = torch.randn((3,12,64))\n",
    "tb(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5495c2e9-f709-4e37-86cc-10dc18d51dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 vocab_size:int = 32,\n",
    "                 block_size:int = 64,\n",
    "                 embedding_dims:int = 64,\n",
    "                 att_heads:int = 8,\n",
    "                 layers:int = 3,\n",
    "                 dropout:float = 0.1\n",
    "                ):\n",
    "        \n",
    "        super(DecoderTransformer, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.block_size = block_size\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.att_heads = att_heads\n",
    "        \n",
    "        self.sequence = nn.Sequential(\n",
    "            nn.Embedding(self.vocab_size, self.embedding_dims),\n",
    "            PositionalEncoder(self.embedding_dims, self.block_size), # maybe just change this to an embedding too\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Sequential(*[TransformerBlock(self.att_heads, self.embedding_dims, self.block_size) for _ in range(layers)]),\n",
    "            nn.LayerNorm(self.embedding_dims)\n",
    "        )\n",
    "        \n",
    "        self.lm_head = nn.Linear(self.embedding_dims, self.vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.sequence(x)\n",
    "        return self.lm_head(x)\n",
    "\n",
    "model = DecoderTransformer()\n",
    "x = torch.randint(31, (4,64))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b202b80-2643-4dec-8ea5-d851ba179aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('./names.txt').read().splitlines()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2870af15-9e49-45d9-b4e2-d1f2b9808a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words)))) #lol\n",
    "token_lookup = {c: i+1 for i, c in enumerate(chars)}\n",
    "token_lookup['.'] = 0\n",
    "char_lookup = {i:c for c, i in token_lookup.items()}\n",
    "TOTAL_TOKENS = len(char_lookup.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a43434ea-0470-4f69-bad6-0b29f23fb3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182413, 8]) torch.Size([182413])\n",
      "torch.Size([22947, 8]) torch.Size([22947])\n",
      "torch.Size([22786, 8]) torch.Size([22786])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "BLOCK_SIZE = 8 # context size to give the model in order to predict the next character\n",
    "\n",
    "def build_dataset(corpus, block_size, codebook, padding_char=\".\"):\n",
    "    X, Y = [], []\n",
    "    for word in corpus:\n",
    "        start_padding = padding_char * block_size\n",
    "        padded_word = f\"{start_padding}{word}.\"\n",
    "        tokenized_word = [codebook[c] for c in padded_word]\n",
    "        for i in range(len(tokenized_word)-block_size):\n",
    "            X.append(tokenized_word[i:i+block_size])\n",
    "            Y.append(tokenized_word[i+block_size])\n",
    "        \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    \n",
    "    print(X.shape, Y.shape)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "random.shuffle(words)\n",
    "\n",
    "n1 = int(len(words)*0.8)\n",
    "n2 = int(len(words)*0.9)\n",
    "\n",
    "x_train, y_train = build_dataset(words[:n1], BLOCK_SIZE, token_lookup)\n",
    "x_valid, y_valid = build_dataset(words[n1:n2], BLOCK_SIZE, token_lookup)\n",
    "x_test, y_test = build_dataset(words[n2:], BLOCK_SIZE, token_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90bb7a4-5811-4e7d-92bd-3a2bbe94f5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 2.10:  39%|█████████████████████████████████████████████████████████▍                                                                                          | 3877/10000 [00:34<00:49, 123.12it/s]"
     ]
    }
   ],
   "source": [
    "model = DecoderTransformer()\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "device = 'cuda:1'\n",
    "steps = 10000\n",
    "print_steps = 2000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "losses = []\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "pbar = tqdm(range(steps))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for t in pbar:\n",
    "    batch_ix = torch.randint(0, x_train.shape[0], (BATCH_SIZE,))\n",
    "    batch = x_train[batch_ix].to(device)\n",
    "    logits = model(batch).mean(1)\n",
    "    \n",
    "    #plucked_logits = logits[:,0::BLOCK_SIZE].view(-1, logits.shape[-1])\n",
    "    loss = F.cross_entropy(logits, y_train[batch_ix].to(device))\n",
    "    losses.append(loss.item())\n",
    "    pbar.set_description(desc=f'average loss: {(sum(losses[-100:])/100):.2f}')\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "941a75b2-4db7-43b4-95a0-9e9ea6692cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(losses).view(-1, 250).mean(1))\n",
    "plt.title(\"average loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3db0f84-3089-4a26-8aef-9b465211ff88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('train', 1.9874836206436157), ('val', 2.022679090499878))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.train(False)\n",
    "\n",
    "# clculate training and validation loss\n",
    "@torch.no_grad()\n",
    "def calc_loss(x_target, y_target):\n",
    "    logits = model(x_target)\n",
    "    plucked_logits = logits[:,0::BLOCK_SIZE].view(-1, logits.shape[-1])\n",
    "    loss = F.cross_entropy(plucked_logits, y_target)\n",
    "    return loss\n",
    "\n",
    "('train', calc_loss(x_train, y_train).item()), ('val', calc_loss(x_valid, y_valid).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1801a71a-53ff-4acf-823a-ffde1468015b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "janeen\n",
      "elliath\n",
      "caidua\n",
      "kaison\n",
      "fottlee\n",
      "teije\n",
      "nelaha\n",
      "pyllowo\n",
      "rosmon\n",
      "rohzias\n",
      "vingson\n",
      "aelemiza\n",
      "jevemah\n",
      "mayker\n",
      "honzen\n",
      "aislea\n",
      "ontorgose\n",
      "lathiya\n",
      "asanbue\n",
      "annaya\n"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "@torch.no_grad()\n",
    "def sample():\n",
    "    tokens = [0] * BLOCK_SIZE\n",
    "    while True:\n",
    "        cur_tokens = torch.tensor(tokens[-BLOCK_SIZE:]).unsqueeze(0)\n",
    "        logits = model(cur_tokens).squeeze()\n",
    "        probs = F.softmax(logits.mean(0), dim=0)\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "        tokens.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    return \"\".join([char_lookup[t] for t in tokens][BLOCK_SIZE:-1])\n",
    "\n",
    "for i in range(20):\n",
    "    print(sample())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
